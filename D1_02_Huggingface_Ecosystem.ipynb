{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869f918b-2554-4152-857b-1c38a3e12522",
   "metadata": {},
   "source": [
    "# Huggingface Ecosystem Overview\n",
    "\n",
    "Huggingface is a company that has revolutionized the field of Natural Language Processing (NLP) by providing an open-source library and tools that facilitate the use of state-of-the-art models for various NLP tasks.\n",
    "\n",
    "### Key Components of the Huggingface Ecosystem:\n",
    "\n",
    "1. **Transformers**: A library that provides APIs and tools to easily download and fine-tune state-of-the-art pre-trained models.\n",
    "2. **Datasets**: A library to access and process large datasets used for NLP and other machine learning tasks.\n",
    "3. **PEFT (Parameter-Efficient Fine-Tuning)**: A library for efficient model fine-tuning using parameter-efficient techniques.\n",
    "4. **Accelerate**: A library to accelerate PyTorch and TensorFlow models' training and deployment across multiple devices (GPUs).\n",
    "5. **Huggingface Hub**: A central repository for pre-trained models, datasets, and metrics, allowing seamless sharing and collaboration.\n",
    "\n",
    "Let's explore each component in detail with hands-on examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4c4d1-370f-4c16-a565-b4d5fd8ebce4",
   "metadata": {},
   "source": [
    "## Transformers Library\n",
    "\n",
    "The `transformers` library by Huggingface is a powerful toolkit that provides state-of-the-art pre-trained models and easy-to-use APIs for NLP tasks such as text classification, named entity recognition, translation, text generation, and more.\n",
    "\n",
    "### Key Features:\n",
    "- Provides thousands of pre-trained models.\n",
    "- Supports multiple frameworks: PyTorch, TensorFlow, and JAX.\n",
    "- Easy integration with the Huggingface Hub.\n",
    "\n",
    "### Example: Loading a Pre-trained Model and Running Inference\n",
    "Let's load a pre-trained BERT model and use it for a simple text classification task.\n",
    "For that we use `pipeline()`.\n",
    "`pipeline()` is a very convenient way to use a pretrained model for inference. You can use the `pipeline()` out-of-the-box for many tasks across different modalities, as can be seen [here](https://huggingface.co/docs/transformers/quicktour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa7e310-283a-4f50-abc9-95b48754a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at /leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/distilbert--distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained sentiment-analysis pipeline\n",
    "# classifier = pipeline(\"sentiment-analysis\") This would determine which model should be used for us.\n",
    "# However, I would like to go easy on our disk space available and use model, which I have downloaded in advance to a shared directory:\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/distilbert--distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb4fae5-4e0b-4dec-a819-133af6687efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: /leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/distilbert--distilbert-base-uncased\n",
      "\n",
      "DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model used: {classifier.model.name_or_path}\\n\")\n",
    "print(classifier.model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8481c1-06ec-43ed-b5fd-7f11de491ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.517898678779602}]\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline with some example text\n",
    "result = classifier(\"Huggingface is an amazing platform for NLP research!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bda56d-26b2-4686-b81b-0ea95eb22aeb",
   "metadata": {},
   "source": [
    "The result isn't great. This is because we used a model, which doesn't hasen't been fine-tuned for the task.\n",
    "Let's try this one and see how it works:\n",
    "<br>\n",
    "`/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/distilbert--distilbert-base-uncased-finetuned-sst-2-english`\n",
    "\n",
    "Feel free to try out different sentences, also negative ones.\n",
    "Should you have more than one input, pass them as a list. You will then get a list of dictionaries as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e309aae-5281-4496-a4e0-24a0a04194b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.5010508894920349}, {'label': 'LABEL_0', 'score': 0.5165805816650391}]\n"
     ]
    }
   ],
   "source": [
    "result = classifier([\"EuorCC courses are not bad at all. There is lots to gain from them.\",\n",
    "                    \"I think Large Language Models are overrated.\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5b3a0-5abd-439f-bb85-3434364f9299",
   "metadata": {},
   "source": [
    "You can see, that the model not only predicts the sentiment, but also outputs a score, which is a probability that indicates the model's confidence in its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293fb22-5e39-4db2-a423-668547372757",
   "metadata": {},
   "source": [
    "## Datasets Library\n",
    "\n",
    "The `datasets` library provides a lightweight library for easily downloading and using datasets in NLP and other ML domains. It is optimized for both in-memory and out-of-memory (on-disk) use, making it suitable for handling very large datasets.\n",
    "\n",
    "### Key Features:\n",
    "- Access to thousands of datasets in various domains.\n",
    "- Built-in data processing tools such as caching, shuffling, and batching.\n",
    "- Easy integration with the `transformers` library for model training.\n",
    "\n",
    "### Example: Loading and Exploring a Dataset\n",
    "Let's load a sample dataset and explore its content.\n",
    "The **IMDB** dataset is a popular benchmark dataset used for sentiment analysis tasks in natural language processing. It consists of movie reviews from the Internet Movie Database (IMDB) and is specifically designed for binary sentiment classification: determining whether a given movie review expresses a positive or negative sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3d7a02-bc94-4b72-81d6-a625a49c4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the IMDB dataset\n",
    "dataset = load_dataset(\"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/datasets/stanfordnlp--imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751799cb-ccd6-499d-bf29-45a267224d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"This is said to be a personal film for Peter Bogdonavitch. He based it on his life but changed things around to fit the characters, who are detectives. These detectives date beautiful models and have no problem getting them. Sounds more like a millionaire playboy filmmaker than a detective, doesn't it? This entire movie was written by Peter, and it shows how out of touch with real people he was. You're supposed to write what you know, and he did that, indeed. And leaves the audience bored and confused, and jealous, for that matter. This is a curio for people who want to see Dorothy Stratten, who was murdered right after filming. But Patti Hanson, who would, in real life, marry Keith Richards, was also a model, like Stratten, but is a lot better and has a more ample part. In fact, Stratten's part seemed forced; added. She doesn't have a lot to do with the story, which is pretty convoluted to begin with. All in all, every character in this film is somebody that very few people can relate with, unless you're millionaire from Manhattan with beautiful supermodels at your beckon call. For the rest of us, it's an irritating snore fest. That's what happens when you're out of touch. You entertain your few friends with inside jokes, and bore all the rest.\", 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Display the 10th example in the training set\n",
    "print(dataset['train'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2f351ea-702a-4a65-8780-fe2c3e4b12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ebe225-aefa-40a1-8d7f-f8b84fefc0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/google--bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model for binary classification (num_labels=2)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/google--bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477be9ec-41fc-4943-8402-bac5088eb361",
   "metadata": {},
   "source": [
    "The Warning we got is to be expected, because the classification head we added has not been pre-trained and the weights and biases have been newly initialized.\n",
    "\n",
    "The bert-base-uncased model is a general-purpose, pre-trained BERT model. It has been trained on a large corpus of text using self-supervised objectives (like masked language modeling) but not for specific tasks like sentiment analysis, classification, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c2956f-8141-4c4b-85b4-4ea896b19a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRA for efficient fine-tuning\n",
    "config = LoraConfig(r=8)\n",
    "peft_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65bc53-16a6-4941-8023-f17dcd1d7779",
   "metadata": {},
   "source": [
    "`get_peft_model` is a function from the PEFT library that takes a pre-trained model and a LoRA configuration (`LoraConfig`) and returns a new model that has been adapted for parameter-efficient fine-tuning.\n",
    "The new model (`peft_model`) has the same architecture as the original model (model) but with additional parameters introduced by LoRA that enable efficient fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde9af54-809e-49fc-8450-d217dd133a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "dataset = load_dataset(\"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/datasets/stanfordnlp--imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e7dc50a-3108-4f81-a0b6-a8bf77ecad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/google--bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d41bfd6-e79a-4bda-8484-db7b0bbb7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5999d9c-39a2-46e5-ad17-b38179d80233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ca2ebec84949548b6d73913e8c8190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format to include PyTorch tensors for input_ids, attention_mask, and label\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")  # Rename 'label' column to 'labels'\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f2da5a4-7154-4f74-8240-512d1ec18ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(output_dir=\"./results\",\n",
    "                                  num_train_epochs=1,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  report_to=\"none\",\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb74a845-84df-4547-a8cb-ff049a23d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-08 10:16:49,867] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-09-08 10:16:52,182] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 01:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.653100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=782, training_loss=0.6041818799265205, metrics={'train_runtime': 76.3213, 'train_samples_per_second': 327.563, 'train_steps_per_second': 10.246, 'total_flos': 1650106406400000.0, 'train_loss': 0.6041818799265205, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(model=peft_model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=tokenized_datasets['train'],\n",
    "                  eval_dataset=tokenized_datasets['test'])\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858ddfb-7266-4dc5-b2d1-2e93e2770c91",
   "metadata": {},
   "source": [
    "## Huggingface Hub\n",
    "\n",
    "The Huggingface Hub is a platform for sharing models, datasets, and demos. It allows developers and researchers to collaborate, publish, and discover models and datasets, making the entire community's work more accessible.\n",
    "\n",
    "### Key Features:\n",
    "- A central repository for models, datasets, and metrics.\n",
    "- Tools for versioning, collaboration, and deployment.\n",
    "- Integrated with Huggingface libraries for easy use.\n",
    "\n",
    "### Example: Uploading a Model to the Huggingface Hub\n",
    "Here's how you can upload a model to the Huggingface Hub.\n",
    "\n",
    "``` python\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Initialize the API\n",
    "api = HfApi()\n",
    "\n",
    "# Example of creating a new repository (Requires authentication)\n",
    "repo_name = \"my-awesome-model\"\n",
    "api.create_repo(repo_name)\n",
    "\n",
    "# Save model locally and push to hub\n",
    "model.save_pretrained(f\"./{repo_name}\")\n",
    "api.upload_folder(repo_id=repo_name, folder_path=f\"./{repo_name}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04781ed0-9729-47ab-9b64-5f14a0716bc4",
   "metadata": {},
   "source": [
    "### Explore Available Models\n",
    "\n",
    "We will use the Huggingface API to search for available models and filter them based on certain criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b36aa4a-1f6a-44ca-a1be-7c7d6342bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4203ce2d-9dd6-4a12-bf7e-7628e3d64074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Huggingface API\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5beccaf-410f-4c0e-8728-5fae880b2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for models in the Huggingface Model Hub\n",
    "models = list(api.list_models(limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28fd92d8-796e-4eaf-b226-4831a4732c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tencent/Hunyuan-MT-7B\n",
      "tencent/HunyuanWorld-Voyager\n",
      "google/embeddinggemma-300m\n",
      "microsoft/VibeVoice-1.5B\n",
      "moonshotai/Kimi-K2-Instruct-0905\n",
      "swiss-ai/Apertus-8B-Instruct-2509\n",
      "meituan-longcat/LongCat-Flash-Chat\n",
      "openbmb/MiniCPM4.1-8B\n",
      "apple/FastVLM-0.5B\n",
      "Qwen/Qwen-Image-Edit\n"
     ]
    }
   ],
   "source": [
    "# Display the fetched models\n",
    "for model in models:\n",
    "    print(model.modelId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0111f01b-8a5d-4059-9d74-f275b2c16a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelInfo(id='tencent/Hunyuan-MT-7B', author=None, sha=None, created_at=datetime.datetime(2025, 8, 28, 9, 51, 39, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=4181, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=549, library_name='transformers', tags=['transformers', 'safetensors', 'hunyuan_v1_dense', 'text-generation', 'translation', 'zh', 'en', 'fr', 'pt', 'es', 'ja', 'tr', 'ru', 'ar', 'ko', 'th', 'it', 'de', 'vi', 'ms', 'id', 'tl', 'hi', 'pl', 'cs', 'nl', 'km', 'my', 'fa', 'gu', 'ur', 'te', 'mr', 'he', 'bn', 'ta', 'uk', 'bo', 'kk', 'mn', 'ug', 'arxiv:2509.05209', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='translation', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=533, siblings=None, spaces=None, safetensors=None, security_repo_status=None, xet_enabled=None),\n",
       " ModelInfo(id='tencent/HunyuanWorld-Voyager', author=None, sha=None, created_at=datetime.datetime(2025, 8, 27, 9, 32, 6, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=3548, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=482, library_name='hunyuanworld-voyager', tags=['hunyuanworld-voyager', 'safetensors', 'hunyuan3d', 'worldmodel', '3d-aigc', '3d-generation', '3d', 'scene-generation', 'image-to-video', 'en', 'zh', 'arxiv:2506.04225', 'license:other', 'region:us'], pipeline_tag='image-to-video', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=482, siblings=None, spaces=None, safetensors=None, security_repo_status=None, xet_enabled=None),\n",
       " ModelInfo(id='google/embeddinggemma-300m', author=None, sha=None, created_at=datetime.datetime(2025, 7, 17, 19, 53, 55, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=35543, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=407, library_name='sentence-transformers', tags=['sentence-transformers', 'safetensors', 'gemma3_text', 'sentence-similarity', 'feature-extraction', 'text-embeddings-inference', 'license:gemma', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='sentence-similarity', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=407, siblings=None, spaces=None, safetensors=None, security_repo_status=None, xet_enabled=None),\n",
       " ModelInfo(id='microsoft/VibeVoice-1.5B', author=None, sha=None, created_at=datetime.datetime(2025, 8, 25, 13, 46, 48, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=230570, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=1549, library_name='transformers', tags=['transformers', 'safetensors', 'vibevoice', 'text-generation', 'Podcast', 'text-to-speech', 'en', 'zh', 'arxiv:2508.19205', 'arxiv:2412.08635', 'license:mit', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='text-to-speech', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=402, siblings=None, spaces=None, safetensors=None, security_repo_status=None, xet_enabled=None),\n",
       " ModelInfo(id='moonshotai/Kimi-K2-Instruct-0905', author=None, sha=None, created_at=datetime.datetime(2025, 9, 3, 3, 34, 36, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=3838, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=287, library_name='transformers', tags=['transformers', 'safetensors', 'kimi_k2', 'text-generation', 'conversational', 'custom_code', 'license:other', 'autotrain_compatible', 'endpoints_compatible', 'fp8', 'region:us'], pipeline_tag='text-generation', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=287, siblings=None, spaces=None, safetensors=None, security_repo_status=None, xet_enabled=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 models for demonstration\n",
    "models[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b06c4-f6ed-4190-978c-c7de60c33b1d",
   "metadata": {},
   "source": [
    "Should you with to make that visually more pleasing, you can do so, by creating a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "373fd47d-fac4-4ea6-bf6c-ddbb99b490ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "070ed909-632a-40b1-aa46-0d21233aa3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame by first creating a dictionary:\n",
    "model_data = []\n",
    "\n",
    "for model in models:\n",
    "    model_info = {\n",
    "        'Model ID': model.modelId,\n",
    "        'Tags': ', '.join(model.tags) if model.tags else 'N/A',\n",
    "        'Downloads': model.downloads,\n",
    "        'Likes': model.likes,\n",
    "        'Pipeline Tag': model.pipeline_tag if model.pipeline_tag else 'N/A',\n",
    "        'Last Modified': model.lastModified.strftime('%Y-%m-%d') if model.lastModified else 'N/A'\n",
    "    }\n",
    "    model_data.append(model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a88db43-e578-4897-9798-801612f8d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Pipeline Tag</th>\n",
       "      <th>Last Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tencent/Hunyuan-MT-7B</td>\n",
       "      <td>transformers, safetensors, hunyuan_v1_dense, t...</td>\n",
       "      <td>4181</td>\n",
       "      <td>549</td>\n",
       "      <td>translation</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tencent/HunyuanWorld-Voyager</td>\n",
       "      <td>hunyuanworld-voyager, safetensors, hunyuan3d, ...</td>\n",
       "      <td>3548</td>\n",
       "      <td>482</td>\n",
       "      <td>image-to-video</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/embeddinggemma-300m</td>\n",
       "      <td>sentence-transformers, safetensors, gemma3_tex...</td>\n",
       "      <td>35543</td>\n",
       "      <td>407</td>\n",
       "      <td>sentence-similarity</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/VibeVoice-1.5B</td>\n",
       "      <td>transformers, safetensors, vibevoice, text-gen...</td>\n",
       "      <td>230570</td>\n",
       "      <td>1549</td>\n",
       "      <td>text-to-speech</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moonshotai/Kimi-K2-Instruct-0905</td>\n",
       "      <td>transformers, safetensors, kimi_k2, text-gener...</td>\n",
       "      <td>3838</td>\n",
       "      <td>287</td>\n",
       "      <td>text-generation</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model ID  \\\n",
       "0             tencent/Hunyuan-MT-7B   \n",
       "1      tencent/HunyuanWorld-Voyager   \n",
       "2        google/embeddinggemma-300m   \n",
       "3          microsoft/VibeVoice-1.5B   \n",
       "4  moonshotai/Kimi-K2-Instruct-0905   \n",
       "\n",
       "                                                Tags  Downloads  Likes  \\\n",
       "0  transformers, safetensors, hunyuan_v1_dense, t...       4181    549   \n",
       "1  hunyuanworld-voyager, safetensors, hunyuan3d, ...       3548    482   \n",
       "2  sentence-transformers, safetensors, gemma3_tex...      35543    407   \n",
       "3  transformers, safetensors, vibevoice, text-gen...     230570   1549   \n",
       "4  transformers, safetensors, kimi_k2, text-gener...       3838    287   \n",
       "\n",
       "          Pipeline Tag Last Modified  \n",
       "0          translation           N/A  \n",
       "1       image-to-video           N/A  \n",
       "2  sentence-similarity           N/A  \n",
       "3       text-to-speech           N/A  \n",
       "4      text-generation           N/A  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the dictionary to pandas DataFrame:\n",
    "df_models = pd.DataFrame(model_data)\n",
    "\n",
    "# Display the first 5 entries of the DataFrame:\n",
    "df_models.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54fa57-1f74-4de2-ae98-c914f7413874",
   "metadata": {},
   "source": [
    "#### Analyze Model Information\n",
    "\n",
    "Inspect the models to understand their details, such as architecture, number of parameters, and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c2e6aeb-6863-4c8a-9d11-40180f8d58c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: google-bert/bert-base-uncased\n",
      "Description: No description available\n",
      "Framework: fill-mask\n",
      "Tags: ['transformers', 'pytorch', 'tf', 'jax', 'rust', 'coreml', 'onnx', 'safetensors', 'bert', 'fill-mask', 'exbert', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1810.04805', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us']\n"
     ]
    }
   ],
   "source": [
    "# Display information about a specific model\n",
    "model_name = \"bert-base-uncased\"  # Example model\n",
    "model_info = api.model_info(model_name)\n",
    "\n",
    "print(f\"Model: {model_info.modelId}\")\n",
    "print(f\"Description: {model_info.cardData.get('description', 'No description available')}\")\n",
    "print(f\"Framework: {model_info.pipeline_tag}\")\n",
    "print(f\"Tags: {model_info.tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9df14e-6292-4df7-afd7-89c2cab531aa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored the Huggingface ecosystem, including the `transformers`, `datasets`, and Huggingface Hub.\n",
    "We will get to know `PEFT` and `accelerate` in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2518fdea-817b-487e-b882-c6bc942c2eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shut down the kernel\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(restart=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd46d3a-2ab5-4771-a979-6980e17de4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
