{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13af6941-248a-4521-8564-c6958c214fee",
   "metadata": {},
   "source": [
    "## Recap and Skill Test\n",
    "\n",
    "In this notebook, you will recap the skills you've learned about **Quantization, Parameter-Efficient Fine-Tuning (PEFT), and Unsloth** techniques. You will apply these methods to memory-efficiently finetune a lange model.\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "1. **Quantize a Model**: Apply 4-bit quantization when loading a pre-trained model.\n",
    "2. **Parameter-Efficient Fine-Tuning (PEFT)**: Use adapter layers to fine-tune a model efficiently.\n",
    "\n",
    "## Task:\n",
    "\n",
    "1. Choose a different pre-trained model from the Huggingface Hub (e.g., Mistral 7B Instruct).\n",
    "2. Load the model using 4-bit quantization.\n",
    "3. Finetune the model on a dataset of your choice (e.g., vicgalle/alpaca-gpt4).\n",
    "4. Evaluate the model's performance before and after finetuning.\n",
    "\n",
    "### Hints:\n",
    "\n",
    "Some models' tokenizers do not come with a `pad_token`. It might be necessary to manually set the `pad_token` to some other token, e.g.:\n",
    "```\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "```\n",
    "\n",
    "In my example, I am going to use `mistralai/Mistral-7B-Instruct-v0.3`, which is a gated model. You need a Huggingface account and ask for access to the model. Then you need to get an account token from https://huggingface.co/settings/tokens and execute `huggingface-cli login` in a Terminal tab in JupyterHub.\n",
    "\n",
    "If you want to use Mistral 7B Instruct, you can also use the following path so that we do not download the same model 50 times:\n",
    "```\n",
    "'/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/mistralai--Mistral-7B-Instruct-v0.3'\n",
    "```\n",
    "Even if you use the model from the filesystem, I would suggest that you still go to the Huggingface Hub and have a look at the list of models and datasets there. You may also create an account, if you don't have one yet, and run `huggingface-cli login`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f9e67-ce1d-4afb-92fb-8e620f453718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
