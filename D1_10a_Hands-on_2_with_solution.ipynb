{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13af6941-248a-4521-8564-c6958c214fee",
   "metadata": {},
   "source": [
    "## Recap and Skill Test\n",
    "\n",
    "In this notebook, you will recap the skills you've learned about **Quantization, Parameter-Efficient Fine-Tuning (PEFT), and Unsloth** techniques. You will apply these methods to memory-efficiently finetune a lange model.\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "1. **Quantize a Model**: Apply 4-bit quantization when loading a pre-trained model.\n",
    "2. **Parameter-Efficient Fine-Tuning (PEFT)**: Use adapter layers to fine-tune a model efficiently.\n",
    "\n",
    "## Task:\n",
    "\n",
    "1. Choose a different pre-trained model from the Huggingface Hub (e.g., Mistral 7B Instruct).\n",
    "2. Load the model using 4-bit quantization.\n",
    "3. Finetune the model on a dataset of your choice (e.g., vicgalle/alpaca-gpt4).\n",
    "4. Evaluate the model's performance before and after finetuning.\n",
    "\n",
    "### Hints:\n",
    "\n",
    "Some models' tokenizers do not come with a `pad_token`. It might be necessary to manually set the `pad_token` to some other token, e.g.:\n",
    "```\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "```\n",
    "\n",
    "In my example, I am going to use `mistralai/Mistral-7B-Instruct-v0.3`, which is a gated model. You need a Huggingface account and ask for access to the model. Then you need to get an account token from https://huggingface.co/settings/tokens and execute `huggingface-cli login` in a Terminal tab in JupyterHub.\n",
    "\n",
    "If you want to use Mistral 7B Instruct, you can also use the following path so that we do not download the same model 50 times:\n",
    "```\n",
    "'/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/mistralai--Mistral-7B-Instruct-v0.3'\n",
    "```\n",
    "Even if you use the model from the filesystem, I would suggest that you still go to the Huggingface Hub and have a look at the list of models and datasets there. You may also create an account, if you don't have one yet, and run `huggingface-cli login`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a29e6d9-68a4-4be6-96b2-5e1ba2b518ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from accelerate import PartialState\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a95d91-a552-42cc-a943-87e078b80778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a339b9cbcf44ec9a7e187e9b2874391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_id = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "model_id = '/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/mistralai--Mistral-7B-Instruct-v0.3'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation='sdpa',  # 'eager', 'sdpa', or \"flash_attention_2\"\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2a8ceb-e0f7-4f74-bb39-fe8f696a795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2bd0913c3f4d27a3d7f28c908f8d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e60eaa61a949e5b13f9f6f14fd8c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-6ef3991c06080e(â€¦):   0%|          | 0.00/48.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0d174100f240a2b4897e8c52c418b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset('vicgalle/alpaca-gpt4', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9cf701-2f9d-4fe5-a8b8-f3b46cdf238e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'text'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa700be0-f4f2-4c2e-8900-5e3edc828418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62961264-950f-49be-ba67-45b161bdadc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730147302b4c46d7a39a32d943d03a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(lambda entry: {'text_mistral7b': tokenizer.apply_chat_template([\n",
    "    {'role': 'user', 'content': entry['instruction']},\n",
    "    {'role': 'assistant', 'content': entry['output']}\n",
    "], tokenize=False)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91feef1-104e-4dee-a818-50ed7b3058da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n",
       " 'text_mistral7b': '<s>[INST] Give three tips for staying healthy.[/INST] 1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.</s>'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec73eab-cd44-463c-9e65-49807b1cc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    r=16,\n",
    "    lora_alpha=32,  # rule: lora_alpha should be 2*r\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    target_modules='all-linear',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eabf9e97-6f84-4177-bb9e-2ef48a1877a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average_tokens_across_devices is set to True but it is invalid when world size is1. Turn it to False automatically.\n"
     ]
    }
   ],
   "source": [
    "training_arguments = SFTConfig(\n",
    "    output_dir='output/mistral7b-alpaca-gpt4',\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True, # Gradient checkpointing improves memory efficiency, but slows down training,\n",
    "        # e.g. Mistral 7B with PEFT using bitsandbytes:\n",
    "        # - enabled: 11 GB GPU RAM and 8 samples/second\n",
    "        # - disabled: 40 GB GPU RAM and 12 samples/second\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},  # Use newer implementation that will become the default.\n",
    "    optim='adamw_torch',  # 'paged_adamw_32bit' can save GPU memory\n",
    "    learning_rate=2e-4,  # QLoRA suggestions: 2e-4 for 7B or 13B, 1e-4 for 33B or 65B\n",
    "    warmup_steps=200,\n",
    "    lr_scheduler_type='cosine',\n",
    "    logging_strategy='steps',  # 'no', 'epoch' or 'steps'\n",
    "    logging_steps=10,\n",
    "    save_strategy='no',  # 'no', 'epoch' or 'steps'\n",
    "    max_steps=100,\n",
    "    bf16=True,  # mixed precision training\n",
    "    report_to='none',  # disable wandb\n",
    "    dataset_text_field='text_mistral7b',\n",
    "    max_seq_length=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be382fd8-5550-4203-a7b9-305f4f5efbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25372fed27e494aa48acddaac4adece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26baf10b2d14cac94367e775a41cbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a3f47abec84aeba23d6d9363f902ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-05 17:44:04,830] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-09-05 17:44:07,708] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=data,\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3097c846-861a-4f52-806d-62dc1d91c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 7,289,966,592 || trainable%: 0.5754\n"
     ]
    }
   ],
   "source": [
    "if hasattr(trainer.model, \"print_trainable_parameters\"):\n",
    "    trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3388e1ba-f6fc-41ee-b808-019ae3bd5dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.593300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.398200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.122100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.194000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 158.05 seconds\n",
      "Training speed: 5.1 samples/s\n"
     ]
    }
   ],
   "source": [
    "result = trainer.train()\n",
    "\n",
    "# Print statistics:\n",
    "print(f\"Run time: {result.metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"Training speed: {result.metrics['train_samples_per_second']:.1f} samples/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90dee5c-0285-4339-8472-6e86a1b377c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6bf37-c41f-4653-b97c-98ed4ee2aa26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
