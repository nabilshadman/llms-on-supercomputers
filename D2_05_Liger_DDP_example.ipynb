{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b1f163-108f-4587-8b0d-0246158ee528",
   "metadata": {},
   "source": [
    "# Liger kernel example with DDP, Mistral 7B instruct and openassistant-guanaco dataset\n",
    "\n",
    "In the first course, we demonstrated a speed-up by using the *unsloth* library, which contains optimized GPU kernels created by manually deriving all compute heavy math steps. *Unsloth* only works for single GPU training though. Another library that also offers optimised GPU kernels is *liger*, which has the advantage that it can also be used for multi-GPU training.\n",
    "\n",
    "In this notebook, we demonstrate finetuning of *Mistral 7B instruct* on two GPUs using DDP and *liger kernels*. The same script is run twice, once with without and once with *liger kernels* in order to compare speed and memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9ee84-e29b-4c05-b124-50e735033760",
   "metadata": {},
   "source": [
    "#### First, we write the python code to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565c4533-5104-4a7c-a688-8b6acb72e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing llama_guanaco_ddp_liger.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile llama_guanaco_ddp_liger.py\n",
    "# Import libraries\n",
    "import torch\n",
    "from accelerate import PartialState\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import pynvml\n",
    "import sys\n",
    "\n",
    "if len(sys.argv) >= 2 and sys.argv[1] == '--enable-liger':\n",
    "    enable_liger = True\n",
    "    print('Using liger kernels.')\n",
    "else:\n",
    "    enable_liger = False\n",
    "    print('Not using liger kernels.')\n",
    "\n",
    "# Import liger kernels and apply automatic monkey-patching to models:\n",
    "# from liger_kernel.transformers import apply_liger_kernel_to_phi3\n",
    "# apply_liger_kernel_to_phi3()\n",
    "# https://github.com/linkedin/Liger-Kernel?tab=readme-ov-file#getting-started\n",
    "from liger_kernel.transformers import AutoLigerKernelForCausalLM\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    pynvml.nvmlInit()\n",
    "    device_count = pynvml.nvmlDeviceGetCount()\n",
    "    memory_used = []\n",
    "    for device_index in range(device_count):\n",
    "        device_handle = pynvml.nvmlDeviceGetHandleByIndex(device_index)\n",
    "        device_info = pynvml.nvmlDeviceGetMemoryInfo(device_handle)\n",
    "        memory_used.append(device_info.used/1024**3)\n",
    "    print('Memory occupied on GPUs: ' + ' + '.join([f'{mem:.1f}' for mem in memory_used]) + ' GB.')\n",
    "\n",
    "\n",
    "# Choose a model and load tokenizer and model (using 4bit quantization):\n",
    "# model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model_name = \"/leonardo_scratch/fast/EUHPC_D20_063/huggingface/models/meta-llama--Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# For multi-GPU training, find out how many GPUs there are and which one we should use:\n",
    "ps = PartialState()\n",
    "num_processes = ps.num_processes\n",
    "process_index = ps.process_index\n",
    "local_process_index = ps.local_process_index\n",
    "\n",
    "if enable_liger:\n",
    "    model = AutoLigerKernelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type='nf4',\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        ),\n",
    "        device_map={'':local_process_index},  # Changed for DDP\n",
    "        attn_implementation='eager',  # 'eager', 'sdpa', or \"flash_attention_2\"\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type='nf4',\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        ),\n",
    "        device_map={'':local_process_index},  # Changed for DDP\n",
    "        attn_implementation='eager',  # 'eager', 'sdpa', or \"flash_attention_2\"\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "\n",
    "# Load the guanaco dataset\n",
    "guanaco_train = load_dataset('/leonardo_scratch/fast/EUHPC_D20_063/huggingface/datasets/timdettmers--openassistant-guanaco', split='train')\n",
    "guanaco_test = load_dataset('/leonardo_scratch/fast/EUHPC_D20_063/huggingface/datasets/timdettmers--openassistant-guanaco', split='test')\n",
    "# guanaco_train = load_dataset('timdettmers/openassistant-guanaco', split='train')\n",
    "# guanaco_test = load_dataset('timdettmers/openassistant-guanaco', split='test')\n",
    "\n",
    "def reformat_text(text, include_answer=True):\n",
    "    question1 = text.split('###')[1].removeprefix(' Human: ')\n",
    "    answer1 = text.split('###')[2].removeprefix(' Assistant: ')\n",
    "    if include_answer:\n",
    "        messages = [\n",
    "            {'role': 'user', 'content': question1},\n",
    "            {'role': 'assistant', 'content': answer1}\n",
    "        ]\n",
    "    else:\n",
    "        messages = [\n",
    "            {'role': 'user', 'content': question1}\n",
    "        ]        \n",
    "    reformatted_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    return reformatted_text\n",
    "\n",
    "# Now, apply reformat_train(..) to both datasets:\n",
    "guanaco_train = guanaco_train.map(lambda entry: {\n",
    "    'reformatted_text': reformat_text(entry['text'])\n",
    "})\n",
    "guanaco_test = guanaco_test.map(lambda entry: {\n",
    "    'reformatted_text': reformat_text(entry['text'])\n",
    "})\n",
    "\n",
    "model.config.use_cache = False  # KV cache can only speed up inference, but we are doing training.\n",
    "\n",
    "# Add low-rank adapters (LORA) to the model:\n",
    "peft_config = LoraConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    r=16,\n",
    "    lora_alpha=32,  # thumb rule: lora_alpha should be 2*r\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    target_modules='all-linear',\n",
    ")\n",
    "# model = get_peft_model(model, peft_config)\n",
    "\n",
    "training_arguments = SFTConfig(\n",
    "    output_dir='output/llama-3.2-1b-instruct-guanaco-ddp-liger',\n",
    "    per_device_train_batch_size=32//num_processes,  # Adjust per-device batch size for DDP\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True, # Gradient checkpointing improves memory efficiency, but slows down training,\n",
    "        # e.g. Mistral 7B with PEFT using bitsandbytes:\n",
    "        # - enabled: 11 GB GPU RAM and 8 samples/second\n",
    "        # - disabled: 40 GB GPU RAM and 12 samples/second\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},  # Use newer implementation that will become the default.\n",
    "    ddp_find_unused_parameters=False,  # Set to False when using gradient checkpointing to suppress warning message.\n",
    "    log_level_replica='error',  # Disable warnings in all but the first process.\n",
    "    optim='adamw_torch',\n",
    "    learning_rate=2e-4,  # QLoRA suggestions: 2e-4 for 7B or 13B, 1e-4 for 33B or 65B\n",
    "    logging_strategy='no',\n",
    "    # logging_strategy='steps',  # 'no', 'epoch' or 'steps'\n",
    "    # logging_steps=10,\n",
    "    save_strategy='no',  # 'no', 'epoch' or 'steps'\n",
    "    # save_steps=2000,\n",
    "    # num_train_epochs=5,\n",
    "    max_steps=20,\n",
    "    bf16=True,  # mixed precision training\n",
    "    report_to='none',  # disable wandb\n",
    "    max_seq_length=1024,\n",
    "    dataset_text_field='reformatted_text',\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=peft_config,\n",
    "    args=training_arguments,\n",
    "    train_dataset=guanaco_train,\n",
    "    eval_dataset=guanaco_test,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "if process_index == 0:  # Only print in first process.\n",
    "    if hasattr(trainer.model, \"print_trainable_parameters\"):\n",
    "        trainer.model.print_trainable_parameters()\n",
    "\n",
    "# eval_result = trainer.evaluate()\n",
    "# if process_index == 0:\n",
    "#     print(\"Evaluation on test dataset before finetuning:\")\n",
    "#     print(eval_result)\n",
    "\n",
    "train_result = trainer.train()\n",
    "if process_index == 0:\n",
    "    print(\"Training result:\")\n",
    "    print(train_result)\n",
    "\n",
    "# eval_result = trainer.evaluate()\n",
    "# if process_index == 0:\n",
    "#     print(\"Evaluation on test dataset after finetuning:\")\n",
    "#     print(eval_result)\n",
    "\n",
    "# Print memory usage once per node:\n",
    "if local_process_index == 0:\n",
    "    print_gpu_utilization()\n",
    "\n",
    "# # Save model in first process only:\n",
    "# if process_index == 0:\n",
    "#     trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9519e17-ec88-4b56-ab1d-1fbc4cb15612",
   "metadata": {},
   "source": [
    "#### Next, we write the SLURM script and submit the script to the scheduler again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c012ab2-b6ad-4078-aa60-a37ada2c8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_llama_guanaco_ddp_liger.slurm\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_llama_guanaco_ddp_liger.slurm\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --partition=boost_usr_prod\n",
    "# #SBATCH --qos=boost_qos_dbg\n",
    "#SBATCH --account=EUHPC_D20_063\n",
    "#SBATCH --reservation=s_tra_ncc\n",
    "\n",
    "## Specify resources:\n",
    "## Leonardo Booster: 32 CPU cores and 4 GPUs per node => request 8 * number of GPUs CPU cores\n",
    "## Leonardo Booster: 512 GB in total => request approx. 120 GB * number of GPUs requested\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --gpus-per-task=2  # up to 4 on Leonardo\n",
    "#SBATCH --ntasks-per-node=1  # always 1\n",
    "#SBATCH --mem=240GB  # should be 120GB * gpus-per-task on Leonardo\n",
    "#SBATCH --cpus-per-task=16  # should be 8 * gpus-per-task on Leonardo\n",
    "\n",
    "#SBATCH --time=0:30:00\n",
    "\n",
    "# Load conda:\n",
    "eval \"$(/leonardo/pub/userexternal/mpfister/miniforge3/bin/conda shell.bash hook)\"\n",
    "conda activate /leonardo/pub/userexternal/mpfister/conda_env_martin24\n",
    "\n",
    "# Include commands in output:\n",
    "set -x\n",
    "\n",
    "# Print current time and date:\n",
    "date\n",
    "\n",
    "# Print host name:\n",
    "hostname\n",
    "\n",
    "# List available GPUs:\n",
    "nvidia-smi\n",
    "\n",
    "# Construct command to run container:\n",
    "# export CONTAINER=\"singularity run --nv --home=$HOME $SINGULARITY_CONTAINER\"\n",
    "# export CONTAINER=\"singularity run --nv --home=$HOME /leonardo/pub/userexternal/mpfister/martin38.sif\"\n",
    "\n",
    "# Set environment variables for communication between nodes:\n",
    "export MASTER_PORT=$(shuf -i 20000-30000 -n 1)  # Choose a random port\n",
    "export MASTER_ADDR=$(scontrol show hostnames ${SLURM_JOB_NODELIST} | head -n 1)\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "# Set launcher and launcher arguments:\n",
    "export LAUNCHER=\"torchrun \\\n",
    "    --nnodes=$SLURM_JOB_NUM_NODES \\\n",
    "    --nproc_per_node=$SLURM_GPUS_ON_NODE \\\n",
    "    --rdzv_id=$SLURM_JOB_ID \\\n",
    "    --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \\\n",
    "    --rdzv_backend=c10d\"\n",
    "# Set training script that will be executed:\n",
    "export PROGRAM=\"llama_guanaco_ddp_liger.py\"\n",
    "\n",
    "# Run:\n",
    "time srun bash -c \"$LAUNCHER $PROGRAM\"\n",
    "time srun bash -c \"$LAUNCHER $PROGRAM --enable-liger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a766c6-f7ec-49f6-a557-aa0b5d8ec357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 19826308\n"
     ]
    }
   ],
   "source": [
    "!sbatch --job-name=$TRAINEE_USERNAME run_llama_guanaco_ddp_liger.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fd35dd-3ba0-4627-a53c-ca6542de7b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          19826308 boost_usr trainee0 a08trb02  R       0:11      1 lrdn0775\n"
     ]
    }
   ],
   "source": [
    "!squeue --name=$TRAINEE_USERNAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40ae43d-dcc6-49b8-8865-88f4a03065d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ date\n",
      "Thu Sep 11 08:07:33 CEST 2025\n",
      "+ hostname\n",
      "lrdn0775.leonardo.local\n",
      "+ nvidia-smi\n",
      "Thu Sep 11 08:07:33 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM-64GB           On  | 00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              64W / 476W |      2MiB / 65536MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM-64GB           On  | 00000000:56:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              61W / 474W |      2MiB / 65536MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "++ shuf -i 20000-30000 -n 1\n",
      "+ export MASTER_PORT=23016\n",
      "+ MASTER_PORT=23016\n",
      "++ scontrol show hostnames lrdn0775\n",
      "++ head -n 1\n",
      "+ export MASTER_ADDR=lrdn0775\n",
      "+ MASTER_ADDR=lrdn0775\n",
      "+ export OMP_NUM_THREADS=16\n",
      "+ OMP_NUM_THREADS=16\n",
      "+ export 'LAUNCHER=torchrun     --nnodes=1     --nproc_per_node=2     --rdzv_id=19826308     --rdzv_endpoint=lrdn0775:23016     --rdzv_backend=c10d'\n",
      "+ LAUNCHER='torchrun     --nnodes=1     --nproc_per_node=2     --rdzv_id=19826308     --rdzv_endpoint=lrdn0775:23016     --rdzv_backend=c10d'\n",
      "+ export PROGRAM=llama_guanaco_ddp_liger.py\n",
      "+ PROGRAM=llama_guanaco_ddp_liger.py\n",
      "+ srun bash -c 'torchrun     --nnodes=1     --nproc_per_node=2     --rdzv_id=19826308     --rdzv_endpoint=lrdn0775:23016     --rdzv_backend=c10d llama_guanaco_ddp_liger.py'\n",
      "Not using liger kernels.\n",
      "Not using liger kernels.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Generating train split: 9846 examples [00:00, 89076.32 examples/s]\n",
      "Generating test split: 518 examples [00:00, 59762.05 examples/s]\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Map: 100%|██████████| 9846/9846 [00:00<00:00, 11173.15 examples/s]\n",
      "Map: 100%|██████████| 9846/9846 [00:00<00:00, 11263.39 examples/s]\n",
      "Map: 100%|██████████| 518/518 [00:00<00:00, 10024.73 examples/s]\n",
      "[rank1]:[W911 08:08:33.309524528 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "Map: 100%|██████████| 9846/9846 [00:05<00:00, 1779.67 examples/s]\n",
      "Map: 100%|██████████| 518/518 [00:00<00:00, 1647.60 examples/s]\n",
      "[rank0]:[W911 08:08:39.593351389 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "/leonardo/pub/userexternal/mpfister/conda_env_martin24/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2025-09-11 08:08:40,177] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Map:   0%|          | 0/518 [00:00<?, ? examples/s]df: /leonardo/home/usertrain/a08trb02/one-click-hpc-access-home-trainee02/.triton/autotune: No such file or directory\n",
      "Map: 100%|██████████| 518/518 [00:00<00:00, 1725.57 examples/s]\n",
      "/leonardo/pub/userexternal/mpfister/conda_env_martin24/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "[2025-09-11 08:08:40,591] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n",
      " 90%|███�{'train_runtime': 44.0428, 'train_samples_per_second': 14.531, 'train_steps_per_second': 0.454, 'train_loss': 1.7684537887573242, 'epoch': 0.06}\n",
      "100%|██████████| 20/20 [00:44<00:00,  2.20s/it]\n",
      "Training result:\n",
      "TrainOutput(global_step=20, training_loss=1.7684537887573242, metrics={'train_runtime': 44.0428, 'train_samples_per_second': 14.531, 'train_steps_per_second': 0.454, 'total_flos': 2781068365135872.0, 'train_loss': 1.7684537887573242, 'epoch': 0.06493506493506493})\n",
      "Memory occupied on GPUs: 58.4 + 36.1 GB.\n",
      "\n",
      "real\t1m55.624s\n",
      "user\t0m0.271s\n",
      "sys\t0m0.010s\n",
      "+ srun bash -c 'torchrun     --nnodes=1     --nproc_per_node=2     --rdzv_id=19826308     --rdzv_endpoint=lrdn0775:23016     --rdzv_backend=c10d llama_guanaco_ddp_liger.py --enable-liger'\n",
      "Using liger kernels.\n",
      "Using liger kernels.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "[rank1]:[W911 08:10:03.213443489 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank0]:[W911 08:10:03.441582946 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "/leonardo/pub/userexternal/mpfister/conda_env_martin24/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2025-09-11 08:10:03,864] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/leonardo/pub/userexternal/mpfister/conda_env_martin24/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "[2025-09-11 08:10:03,989] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n",
      " 90%|███�{'train_runtime': 35.6166, 'train_samples_per_second': 17.969, 'train_steps_per_second': 0.562, 'train_loss': 1.7831192016601562, 'epoch': 0.06}\n",
      "100%|██████████| 20/20 [00:35<00:00,  1.78s/it]\n",
      "Training result:\n",
      "TrainOutput(global_step=20, training_loss=1.7831192016601562, metrics={'train_runtime': 35.6166, 'train_samples_per_second': 17.969, 'train_steps_per_second': 0.562, 'total_flos': 2781068365135872.0, 'train_loss': 1.7831192016601562, 'epoch': 0.06493506493506493})\n",
      "Memory occupied on GPUs: 19.7 + 24.4 GB.\n",
      "\n",
      "real\t1m13.241s\n",
      "user\t0m0.272s\n",
      "sys\t0m0.004s\n"
     ]
    }
   ],
   "source": [
    "!cat slurm-19826308.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd8745-c6fc-4b26-b5f1-34c245e840d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e102f7d9-ca9f-486e-937e-c3ee3a09fc40",
   "metadata": {},
   "source": [
    "#### Finally, we can clean up and delete the files that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a52fe7c-9bfe-45d0-84ed-9287c9c84f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'slurm-*.out': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm llama_guanaco_ddp_liger.py run_llama_guanaco_ddp_liger.slurm slurm-*.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b7d0b-924a-46f1-a23f-42ee5964dfec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
